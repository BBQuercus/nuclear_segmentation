{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Stardist Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stardist model is used to create instance masks for a subsequent watershed. The main drawback of stardist is that one doesn't get accurate cell borders due to the limited number of polygons (depending on computational expenses). Therefore, this model 'only' operates with 32 angles. For details on how to install stardist, please check out their [Github](https://github.com/mpicbg-csbd/stardist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "import datetime\n",
    "import skimage\n",
    "\n",
    "import utils.dirtools\n",
    "import utils.data_provider\n",
    "import utils.augmentation\n",
    "import stardist\n",
    "from stardist.models import Config2D\n",
    "\n",
    "lbl_cmap = stardist.random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Stardist doesn't allow for runtime reading of images, we have to import them here. The `stardist_importer` import the images and normalizes them for the network to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '.data/train_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import paths\n",
    "X = sorted(glob.glob(f'{root}/images/*.tif'))\n",
    "Y = sorted(glob.glob(f'{root}/masks/*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / valid split\n",
    "x_train, x_valid, y_train, y_valid = utils.dirtools.train_valid_split(x_list=X, y_list=Y, valid_split=0.2)\n",
    "\n",
    "# Import images – stardist doesnt allow for runtime reading\n",
    "x_train, y_train = utils.data_provider.stardist_importer(x_train, y_train)\n",
    "x_valid, y_valid = utils.data_provider.stardist_importer(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "ix = np.random.randint(0, len(X)-1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].imshow(skimage.io.imread(X[ix]))\n",
    "ax[0].set_title(f'Original Image – #{ix}')\n",
    "ax[1].imshow(skimage.io.imread(Y[ix]), cmap=lbl_cmap)\n",
    "ax[1].set_title('Ground Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters and augmentations can be changed below. We decided on the number of rays as 32 due to stardists reccomendations as can be seen [here](https://nbviewer.jupyter.org/github/mpicbg-csbd/stardist/blob/master/examples/2D/1_data.ipynb). If the starnet model passes some more tests, one could probably decrease the number of rays to 16 or 8 as only the centroid location is actually used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Config2D.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "conf = Config2D (\n",
    "    train_epochs = 4, # 400,\n",
    "    train_steps_per_epoch = 10, # 100,\n",
    "    n_rays = 32,\n",
    "    grid = (2, 2),\n",
    "    use_gpu = False, #and gputools_available(),\n",
    "    unet_n_depth = 3,\n",
    "    n_channel_in = 1 if x_train[0].ndim==2 else x_train[0].shape[-1],\n",
    "    train_patch_size = (256, 256),\n",
    ")\n",
    "\n",
    "# ImageDataGenerator\n",
    "data_gen_args = dict(horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     rotation_range=90,\n",
    "                     zoom_range=0.5,\n",
    "                     shear_range=0.5,\n",
    "                     width_shift_range=0.5,\n",
    "                     height_shift_range=0.5,\n",
    "                     fill_mode='reflect',\n",
    "                     data_format='channels_last')\n",
    "\n",
    "#vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"{datetime.date.today().strftime('%Y%m%d')}_Star\"\n",
    "model = stardist.models.StarDist2D(conf, name=model_name, basedir='./models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filed of view size\n",
    "median_size = stardist.calculate_extents(list(y_train), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print('Median object size > FOV') if any(median_size > fov) else print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to [http://localhost:6006/](http://localhost:6006/) after activating tensorboard.\n",
    "\n",
    "    $ tensorboard --logdir=.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train, y_train,\n",
    "            validation_data=(x_valid, y_valid),\n",
    "            augmenter=utils.augmentation.StarAugment(**data_gen_args).augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(x_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
